{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-03T15:20:33.728735Z","iopub.status.busy":"2022-08-03T15:20:33.728215Z","iopub.status.idle":"2022-08-03T15:20:36.910671Z","shell.execute_reply":"2022-08-03T15:20:36.909822Z","shell.execute_reply.started":"2022-08-03T15:20:33.728478Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['list-of-prescription-drug-brand-names.zip', 'drugnames-20220512-parquet.gzip', 'drugname.txt']\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir('datasets/data/Drugnames'))\n","\n","import sys\n","import re\n","import numpy as np\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","\n","# Any results you write to the current directory are saved as output.\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"source":["This is a fun exercise I made for myself to generate hypothetical brand names for prescription drugs starting with a list of existing drug names and an LSTM (long short-term memory) neural net.  The LSTM implementation uses  the Keras package, and was inspired by Jason Brownlee's neural net for generating text from Alice in Wonderland, found [here](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)."]},{"cell_type":"markdown","metadata":{"_uuid":"07b6ff308bb88f02f9da4389f0aec5caf891e243"},"source":["## Data\n","\n","The format of the data set is a list of prescription drug brand names, stored in a text file, each separated by the character '#', which denotes the beginning/end of a word."]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"82d0d4b563d578555347564b62e3c3e44bbb2296","execution":{"iopub.execute_input":"2022-08-03T15:20:19.926660Z","iopub.status.busy":"2022-08-03T15:20:19.926305Z","iopub.status.idle":"2022-08-03T15:20:19.942826Z","shell.execute_reply":"2022-08-03T15:20:19.941877Z","shell.execute_reply.started":"2022-08-03T15:20:19.926588Z"},"trusted":true},"outputs":[],"source":["\n","\"\"\"\n","Load the data file.  The data file consists of drug names separated by special character '#'\n","\"\"\"\n","filename = 'datasets/data/Drugnames/drugname.txt'\n","raw_text = open(filename).read()\n","raw_text = raw_text.lower()"]},{"cell_type":"markdown","metadata":{"_uuid":"734495bc1468fae7c5fdfc96fa9e37a61b716f5f"},"source":["We need to featurize our data.  We'll use a time series approach, carving our data up into sequences of 10-character strings that predict the 11th.  So the training looks like like this:\n","\n","| Input        | Output           |\n","| ------------- |:-------------:|\n","| #iclusig#a      | c |\n","| iclusig#ac      | z      |\n","| clusig#acz | o      |\n","| lusig#aczo | n      |\n","| usig#aczon | e      |\n","| sig#aczone | #      |"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"3758529add4c0f2ba15f32f9c5851b7e8c12111a","execution":{"iopub.execute_input":"2022-08-03T15:20:45.665654Z","iopub.status.busy":"2022-08-03T15:20:45.665285Z","iopub.status.idle":"2022-08-03T15:20:45.801039Z","shell.execute_reply":"2022-08-03T15:20:45.799806Z","shell.execute_reply.started":"2022-08-03T15:20:45.665581Z"},"trusted":true},"outputs":[],"source":["\n","alphabet = 'abcdefghijklmnopqrstuvwxyz-.#'\n","char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n","int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n","\n","n_chars = len(raw_text)\n","\n","seq_length = 10\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length):\n","\tseq_in = raw_text[i:i + seq_length]\n","\tseq_out = raw_text[i + seq_length]\n","\tdataX.append([char_to_int[char] for char in seq_in])\n","\tdataY.append(char_to_int[seq_out])\n","\n","# X is the input data (time series of 10-character strings)\n","X = np.reshape(dataX, (len(dataX), seq_length, 1))\n","\n","# y is the output data (the 11th character to be predicted from the preceding 10)\n","y = np_utils.to_categorical(dataY)\n"]},{"cell_type":"markdown","metadata":{"_uuid":"c00953c90e429b17d7810b2ba37ef5ff88f25ba6"},"source":["Now we define our LSTM model and fit it to the data."]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"d2bfdf6dd53236cd4c8a3614422410c6704d139d","execution":{"iopub.execute_input":"2022-08-03T07:00:15.193189Z","iopub.status.busy":"2022-08-03T07:00:15.192539Z","iopub.status.idle":"2022-08-03T07:03:10.634713Z","shell.execute_reply":"2022-08-03T07:03:10.633763Z","shell.execute_reply.started":"2022-08-03T07:00:15.193134Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-08-03 19:16:28.812340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:28.818732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:28.818946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:28.819527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-08-03 19:16:28.820320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:28.820499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:28.820652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:29.265119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:29.265392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:29.265581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-03 19:16:29.265706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2843 MB memory:  -> device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2022-08-03 19:16:31.050619: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n"]},{"name":"stdout","output_type":"stream","text":["83/83 [==============================] - 2s 6ms/step - loss: 3.0039\n","Epoch 2/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.9261\n","Epoch 3/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.8824\n","Epoch 4/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.8445\n","Epoch 5/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.8037\n","Epoch 6/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.7875\n","Epoch 7/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.7667\n","Epoch 8/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.7530\n","Epoch 9/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.7429\n","Epoch 10/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.7337\n","Epoch 11/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.7248\n","Epoch 12/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.7130\n","Epoch 13/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.7093\n","Epoch 14/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.6991\n","Epoch 15/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.6900\n","Epoch 16/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6839\n","Epoch 17/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.6812\n","Epoch 18/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.6709\n","Epoch 19/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6619\n","Epoch 20/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6454\n","Epoch 21/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6438\n","Epoch 22/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.6321\n","Epoch 23/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.6233\n","Epoch 24/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6156\n","Epoch 25/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.6026\n","Epoch 26/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.5903\n","Epoch 27/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.5725\n","Epoch 28/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.5619\n","Epoch 29/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.5557\n","Epoch 30/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.5492\n","Epoch 31/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.5175\n","Epoch 32/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.5008\n","Epoch 33/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.4808\n","Epoch 34/50\n","83/83 [==============================] - 1s 6ms/step - loss: 2.4739\n","Epoch 35/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.4499\n","Epoch 36/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.4198\n","Epoch 37/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.4020\n","Epoch 38/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.3750\n","Epoch 39/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.3551\n","Epoch 40/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.3289\n","Epoch 41/50\n","83/83 [==============================] - 0s 6ms/step - loss: 2.2944\n","Epoch 42/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.2708\n","Epoch 43/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.2398\n","Epoch 44/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.1965\n","Epoch 45/50\n","83/83 [==============================] - 1s 7ms/step - loss: 2.1671\n","Epoch 46/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.1270\n","Epoch 47/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.1076\n","Epoch 48/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.0668\n","Epoch 49/50\n","83/83 [==============================] - 0s 5ms/step - loss: 2.0273\n","Epoch 50/50\n","83/83 [==============================] - 0s 6ms/step - loss: 1.9768\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f946c735660>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model = Sequential()\n","model.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","model.fit(X, y, epochs=50, batch_size=100)"]},{"cell_type":"markdown","metadata":{"_uuid":"5d1e8b44ffe8a98f0331f0ea7780efc451376cc1"},"source":["From the trained model we can generate predictions of arbitrary length to follow any given string from the input data, from which complete names can be extracted.  Below we will generate predicted strings of length 25, then extract the first complete word from each string, until there are 100 acceptable candidates, and then print those 100 candidates.  What is acceptable is determined by a couple of post-hoc filters."]},{"cell_type":"markdown","metadata":{"_uuid":"dc3d5c75fb336755e9c40295e76373f078ec6c4c"},"source":["## Output filters\n","\n","The neural net has a real thing for double letters, and thus I filter the output to exclude names with double letters.  I also filter the output to exclude existing drug names from the input data as well as duplicate generated names.  Finally, I implement a filter that excludes candidates whose consonant-to-vowel ratio is not strictly between 0.5 and 2.  This filters out many of the phonologically impossible candidates."]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"abaf29ef811cb3e86857b239a731f6c6f9dd1a25","execution":{"iopub.execute_input":"2022-08-03T07:03:19.894897Z","iopub.status.busy":"2022-08-03T07:03:19.894592Z","iopub.status.idle":"2022-08-03T07:03:19.910765Z","shell.execute_reply":"2022-08-03T07:03:19.909922Z","shell.execute_reply.started":"2022-08-03T07:03:19.894860Z"},"trusted":true},"outputs":[],"source":["# this regexp matches double letters... you get more realistic results if you filter out double letters\n","regexp = re.compile(r\"(.)\\1\")\n","\n","# define what consonants and vowels are\n","vowl = 'aeiou'\n","cons = 'bcdfghjklmnpqrstvwxz'\n","\n","# function below filters results first by double letters then by consonant-to-vowel ratio\n","def realistic(word):\n","    if re.search(regexp, generated_name):\n","        return False\n","    else:\n","        try:\n","            cv_ratio = len([char for char in word if char in cons]) / len([char for char in word if char in vowl]) + 0.001\n","        except ZeroDivisionError:\n","            return False\n","        if cv_ratio >= 2:\n","            return False\n","        if cv_ratio <= 0.5:\n","            return False\n","        else:\n","            return True"]},{"cell_type":"markdown","metadata":{"_uuid":"cc6711f94b64e6c882c0aadb63068106b28d0913"},"source":["Below is code for generating 100 names from the model."]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"a4e01e9477ced21d6b653e78c834661d1485ac47","execution":{"iopub.execute_input":"2022-08-03T07:11:27.932912Z","iopub.status.busy":"2022-08-03T07:11:27.932608Z","iopub.status.idle":"2022-08-03T07:11:36.481786Z","shell.execute_reply":"2022-08-03T07:11:36.480942Z","shell.execute_reply.started":"2022-08-03T07:11:27.932874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Eowenta\n","\n","Carinet\n","\n","Pamaten\n","\n","Eninenta\n","\n","Laminta\n","\n","Climea\n","\n","Eobnexa\n","\n","Menatin\n","\n","Aypris\n","\n","Zimata\n","\n","Ciamea\n","\n","Elorane\n","\n","Cariar\n","\n","Jaluva\n","\n","Cilria\n","\n","Ayenma\n","\n","Aldanin\n","\n","Lerinta\n","\n","Novulie\n","\n","Hucamin\n","\n","Elocard\n","\n","Euras\n","\n","Arirint\n","\n","Luerta\n","\n","Clarea\n","\n","Alirisa\n","\n","Alaitin\n","\n","Farine\n","\n","Zisoar\n","\n","Beyaza\n","\n","Clogara\n","\n","Alinta\n","\n","Petaca\n","\n","Cariara\n","\n","Celoear\n","\n","Pepatis\n","\n","Aliaril\n","\n","Venaten\n","\n","Vebliar\n","\n","Alaila\n","\n","Ananiean\n","\n","Crinea\n","\n","Lanuma\n","\n","Cemeta\n","\n","Eloare\n","\n","Hnoera\n","\n","Aleama\n","\n","Elyroe\n","\n","Tesecar\n","\n","Xinara\n","\n","Celaten\n","\n","Flreare\n","\n","Zilace\n","\n","Aloaren\n","\n","Ielact\n","\n","Piratis\n","\n","Vora\n","\n","Cliviza\n","\n","Ratilta\n","\n","Eypiren\n","\n","Fatactil\n","\n","Lubocen\n","\n","Kanzalne\n","\n","Enarei\n","\n","Lusila\n","\n","Lamilta\n","\n","Alarin\n","\n","Pavista\n","\n","Delceta\n","\n","Laruna\n","\n","Voboea\n","\n","Viriva\n","\n","Arixent\n","\n","Penacta\n","\n","Cilrea\n","\n","Alimea\n","\n","Enorent\n","\n","Provia\n","\n","Puilera\n","\n","Ziaga\n","\n","Caracla\n","\n","Ceivis\n","\n","Rymlia\n","\n","Mymari\n","\n","Aneina\n","\n","Virivar\n","\n","Futala\n","\n","Suilare\n","\n","Srolanei\n","\n","Mepacta\n","\n","Verirar\n","\n","Elarex\n","\n","Coiarin\n","\n","Coivert\n","\n","Alomita\n","\n","Sytanei\n","\n","Lutian\n","\n","Levista\n","\n","Humare\n","\n","Arinta\n","\n"]}],"source":["generated_names = []\n","\n","while len(generated_names) < 100:\n","    sequence = list(dataX[np.random.randint(0, len(dataX)-1)])\n","    result = ''\n","    # the for loop starts with a random data point from X, then predicts 25 characters to follow it\n","    for i in range(25):\n","        x = np.reshape(sequence, (1, len(sequence), 1))\n","        prediction = model.predict(x, verbose=0)\n","        index = np.argmax(prediction)\n","        character = int_to_char[index]\n","        result = result + character\n","        sequence.append(index)\n","        sequence = sequence[1:len(sequence)]\n","    # extract the first complete word from the 25-character sequence\n","    generated_name = result.split('#')[1]\n","    \"\"\"\n","    filter words by:\n","    (i) whether they are already in our data,\n","    (ii) whether they have already been generated, and\n","    (iii) whether they are realistic\n","    \"\"\"\n","    if generated_name not in raw_text:\n","        if generated_name not in generated_names:\n","            if realistic(generated_name):\n","                generated_names.append(generated_name)\n","\n","generated_names = [name[0].upper() + name[1:len(name)] for name in generated_names]\n","\n","for name in generated_names:\n","    print(name + '\\n')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('lstm')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"ab40fbdebdf2d1f9df893a6f90003de9edfb5e9488779353396d919544c0be16"}}},"nbformat":4,"nbformat_minor":4}
